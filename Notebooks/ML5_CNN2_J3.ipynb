{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40719c57",
   "metadata": {},
   "source": [
    "# Modules importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30aa27c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 14:48:12.551958: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, decode_predictions\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df4ebcd",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db04db0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results_dic(dic_result):\n",
    "    print(\"Accuracy on test set is:\")\n",
    "    for key, value in dic_result.items():\n",
    "        print(f\"{value*100:.1f}% : {key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c46628b",
   "metadata": {},
   "source": [
    "# Data importation\n",
    "Origin: Kaggle animal_data : [link](https://www.kaggle.com/datasets/likhon148/animal-data/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5907234d",
   "metadata": {},
   "source": [
    "## Split data in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06d7409e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_files(src_dir, dst_dir, files):\n",
    "    # Make sure destination folder exists\n",
    "    os.makedirs(dst_dir, exist_ok=True)\n",
    "    # Loop over selected indices and copy files\n",
    "    for file_name in files:\n",
    "        #file_name = files[idx]\n",
    "        src_path = os.path.join(src_dir, file_name)\n",
    "        dst_path = os.path.join(dst_dir, file_name)\n",
    "        shutil.copy(src_path, dst_path)\n",
    "\n",
    "if not os.path.isdir(\"../Data/animal_data/_train/\"): #If already done doesn't do it again\n",
    "    folder_path = r\"../Data/animal_data/\" # Put the path to your dataset\n",
    "    ratio_train = 0.8 # Ratio of images in the train dataset\n",
    "    ratio_val=0.1 #ratio of images in the validation set in the train set\n",
    "\n",
    "    directories = [name for name in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, name))]\n",
    "    print(\"Directories:\")\n",
    "    print(directories)\n",
    "\n",
    "\n",
    "    for dir in directories: \n",
    "        print(dir)\n",
    "        src_dir = folder_path+dir\n",
    "        files = np.array([f for f in os.listdir(src_dir) if os.path.isfile(os.path.join(src_dir, f))])\n",
    "        \n",
    "        files_train,files_test=train_test_split(files, train_size=ratio_train)\n",
    "        files_train,files_val=train_test_split(files_train, test_size=ratio_val)\n",
    "        \n",
    "        # n_files = len(files)\n",
    "        # train_size = round(ratio_train * n_files)\n",
    "        # idx_train = random.sample(range(n_files), train_size)\n",
    "        # idx_test = list(set(range(n_files)) - set(idx_train))\n",
    "        # idx_val= list(set)\n",
    "        \n",
    "        #TRAIN\n",
    "        dst_dir = folder_path+'_train/'+dir+'/'\n",
    "        copy_files(src_dir, dst_dir, files_train)\n",
    "        \n",
    "        #Validation\n",
    "        dst_dir = folder_path+'_validation/'+dir+'/'\n",
    "        copy_files(src_dir, dst_dir, files_val)\n",
    "\n",
    "        #TEST\n",
    "        dst_dir = folder_path+'_test/'+dir+'/'\n",
    "        copy_files(src_dir, dst_dir, files_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111fc538",
   "metadata": {},
   "source": [
    "## Data loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e14f773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1388 images belonging to 15 classes.\n",
      "Found 161 images belonging to 15 classes.\n",
      "Found 395 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(\n",
    "    #rescale=1/255.0,\n",
    "    rotation_range=0.15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "train_generator=train_datagen.flow_from_directory(\n",
    "    directory=r\"../Data/animal_data/_train/\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=128,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "val_datagen=ImageDataGenerator()\n",
    "val_generator=val_datagen.flow_from_directory(\n",
    "    directory=r\"../Data/animal_data/_validation/\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=128,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_datagen=ImageDataGenerator()\n",
    "test_generator=test_datagen.flow_from_directory(\n",
    "    directory=r\"../Data/animal_data/_test/\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=1,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164a9606",
   "metadata": {},
   "source": [
    "# my CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eea7f114",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn=Sequential([\n",
    "    Input(shape=(224,224,3)),\n",
    "    Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'),\n",
    "    Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'),\n",
    "    Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(15, activation='softmax')\n",
    "])\n",
    "model_cnn.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7de6138b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 8s/step - accuracy: 0.0749 - loss: 2.6830 - val_accuracy: 0.0683 - val_loss: 2.7081\n",
      "Epoch 2/2\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 8s/step - accuracy: 0.0821 - loss: 2.6886 - val_accuracy: 0.0932 - val_loss: 2.7168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7a68581a5bd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn.fit(\n",
    "    train_generator,\n",
    "    epochs=2, validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d823da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.1038 - loss: 2.6356\n",
      "Accuracy on test set is:\n",
      "10.4% : CNN\n"
     ]
    }
   ],
   "source": [
    "dic_scores=dict()\n",
    "dic_scores[\"CNN\"]=model_cnn.evaluate(test_generator)[1]\n",
    "print_results_dic(dic_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f80bd6",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38d63d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=VGG16() #Import the VGG16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b5b336c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "# STEP_SIZE_VAL=val_generator.n//val_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f91815a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit_generator(\n",
    "#     generator=train_generator,\n",
    "#     steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "#     validation_data=val_generator,\n",
    "#     validation_steps=STEP_SIZE_VAL,\n",
    "#     epochs=10\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "821ffcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thibault.launois@Digital-Grenoble.local/anaconda3/envs/ML5/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 143ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_vgg16=model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a34e5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=decode_predictions(y_pred_vgg16)\n",
    "\n",
    "first_predictions=list()\n",
    "for pred in predictions:\n",
    "    first_predictions.append(pred[0][1])\n",
    "\n",
    "first_predictions=np.array(first_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4f07b9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The three most predicted categories by VGG16 are:\n",
      "ice_bear: 12\n",
      "brown_bear: 8\n",
      "American_black_bear: 1\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "print(\"The three most predicted categories by VGG16 are:\")\n",
    "unique_pred=collections.Counter(first_predictions)\n",
    "for animal in list(unique_pred.keys())[:3]:\n",
    "    print(f\"{animal}: {unique_pred[animal]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e799d623",
   "metadata": {},
   "source": [
    "# Transfer learning VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b62c7cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load pre-trained VGG-16 on ImageNet without the last fully-connected layers\n",
    "model_2=VGG16(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
    "\n",
    "# We do not train the layers in VGG16\n",
    "for layer in model_2.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbc64317",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3=Sequential([\n",
    "    model_2,\n",
    "    Flatten(),\n",
    "    Dense(15, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec3c2dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=SGD(learning_rate=0.0001, momentum=0.9),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73453334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 13s/step - accuracy: 0.2788 - loss: 13.8526\n",
      "Epoch 2/2\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 13s/step - accuracy: 0.7133 - loss: 3.7251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7a68a85b3b90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.fit(\n",
    "    train_generator,\n",
    "    epochs=2,\n",
    "    #verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0194f625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 104ms/step - accuracy: 0.8127 - loss: 2.7587\n",
      "Accuracy on test set is:\n",
      "10.4% : CNN\n",
      "81.3% : Augmented VGG16\n"
     ]
    }
   ],
   "source": [
    "dic_scores[\"Augmented VGG16\"]=model_3.evaluate(test_generator)[1]\n",
    "print_results_dic(dic_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e2e1a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
